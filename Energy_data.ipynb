{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Free Energy Calculation applied to HCP dataset\n",
    "*Cyril Rommens, s12495719, masterproject MSc Physics and Astronomy: Computational Physics of Complex Systems*\n",
    "\n",
    "**Introduction**\n",
    "In this notebook, we will use the free energy calculation as explored in the 'Energy_calculation.ipynb'-file following Knill's theorisation on the free energy of a simplicial complex. We will apply this calculation to data from the Human Connectome Project. This data is given in pairwise connectionmatrices, which represent interactions between important regions in the brain. Using the code in 'Connection_matrix.ipynb' we will convert this matrix into the complete connection matrix, including connections between all simplices in the simplicial complex, as required by Knill's theorisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import necessities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import glob\n",
    "import timeit\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import background functions\n",
    "%run \"./Background Scripts/functions.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all matrices to generate averaged data with Numpy or Pandas\n",
    "matrices = [np.genfromtxt(file) for file in glob.glob('./1000_Functional_Connectomes/Connectivity matrices/*_matrix_file.txt')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute the connection probability matrix $L_p$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_p = np.mean(matrices, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate the clique_complex** from a desired subject in the dataset, given a certain threshold and maximum clique size. If the maximum clique size gets too large, the computational cost will increase significantly so for now do not go above 3. **Note** the threshold value does not have any physical meaning for now. Once everything works, finding a physical meaning for the sparseness of the graph is an interesting and important topic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "811\n"
     ]
    }
   ],
   "source": [
    "connection_matrices = []\n",
    "threshold = 0.9  # Set your threshold\n",
    "max_clique_size = 3  # Set the maximum size of the cliques\n",
    "\n",
    "for matrix in matrices:\n",
    "    clique_complex = build_clique_complex(matrix, threshold, max_clique_size)\n",
    "    clique_complex = sorted(clique_complex)\n",
    "    overlap_matrix = generate_overlap_matrix(clique_complex)\n",
    "    connection_matrices.append(overlap_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute the inverse connection matrix ${L_i}^{-1}$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invert matrices for complete dataset\n",
    "L_inverse_list = []\n",
    "removed_rows_list = []\n",
    "\n",
    "for matrix in connection_matrices:\n",
    "    result_matrix, removed_rows, inverse_matrix = inverse_matrix_generator(matrix)\n",
    "    L_inverse_list.append(inverse_matrix)\n",
    "    removed_rows_list.append(removed_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decompress the inverse matrices for later use, since we need to multiply them with the $L_p$ matrix and thus should be of equal dimensions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_inverse_decompressed_list = []\n",
    "\n",
    "for matrix in range(0, len(L_inverse_list)):\n",
    "    decompressed_matrix = decompress(L_inverse_list[matrix], 14, removed_rows_list[matrix])\n",
    "    L_inverse_decompressed_list.append(decompressed_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute the internal energy, entropy and Helmholtz free energy from the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (6,6) (177,177) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5976\\503616688.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Compute the functionals from the dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mU_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mF_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunctionals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatrices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mL_inverse_decompressed_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mL_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m293\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\cyril\\OneDrive\\Documenten\\MSc Physics and Astronomy\\Thesis\\GitHub\\network_TDA_tutorial\\Background Scripts\\functions.py\u001b[0m in \u001b[0;36mfunctionals\u001b[1;34m(G_matrices, L_matrices, L_p, temperature)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[0mF_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mmatrix\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL_matrices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mU\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minternal_energy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL_matrices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mL_p\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[0mU_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mU\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \u001b[0mS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG_matrices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mL_p\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\cyril\\OneDrive\\Documenten\\MSc Physics and Astronomy\\Thesis\\GitHub\\network_TDA_tutorial\\Background Scripts\\functions.py\u001b[0m in \u001b[0;36minternal_energy\u001b[1;34m(inverse_connection_matrix, probability_matrix)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;31m# Compute the internal energy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m     \u001b[0mU\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minverse_connection_matrix\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mprobability_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mU\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (6,6) (177,177) "
     ]
    }
   ],
   "source": [
    "# Compute the functionals from the dataset\n",
    "U_list, S_list, F_list = functionals(matrices, L_inverse_decompressed_list, L_p, 293)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TDA_brain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
