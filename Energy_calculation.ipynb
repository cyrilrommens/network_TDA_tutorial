{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational scheme for the free energy of a simplicial complex\n",
    "*Cyril Rommens, s12495719, masterproject MSc Physics and Astronomy: Computational Physics of Complex Systems*\n",
    "\n",
    "**Introduction**\n",
    "In this notebook, we compute the Free energy of a simplicial complex from a given dataset. First we analyse the dataset to define a connection probability. After this, we can choose a desired simplicial complex G_i from the set with $0<i<N$ complexes and compute the internal energy U and the entropy S, according to Knill's work. From this we can then compute the Helmholtz free energy F."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic data manipulation libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import timeit\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now just give a pre-set dataset\n",
    "import openpyxl\n",
    "import numpy as np\n",
    "\n",
    "# Specify the directory and file name\n",
    "excel_file_path = r'C:\\Users\\cyril\\OneDrive\\Documenten\\MSc Physics and Astronomy\\Thesis\\Planning\\Week 9 - 18 jan\\Dataset_example\\SimplicialComplex_G.xlsx'\n",
    "\n",
    "# Load the Excel file into a Pandas DataFrame\n",
    "G_list = []\n",
    "sheet_list = ['G_A', 'G_B', 'G_C', 'G_D', 'G_E', 'G_F']\n",
    "for sheet in sheet_list:\n",
    "    df = pd.read_excel(excel_file_path, sheet_name=sheet, engine='openpyxl', header=None)\n",
    "    G_i = df.values.astype(np.float64)\n",
    "    G_i = np.nan_to_num(G_i, nan=0)\n",
    "    G_list.append(G_i)\n",
    "\n",
    "# Now, G is a 2D NumPy array containing the data from the first sheet of the Excel file\n",
    "G = np.array(G_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Binarization**\n",
    "\n",
    "Knill reports the connection matrix as binary, so L_xy = 1 if the simplex x intersects with the simplex y and L_xy = 0 if it doesnâ€™t. So there is no degree in connectivity. Binarize the matrices in further calculations for now, to first work out the method according to Knill, without connectivity degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.0\n",
    "G_binary = (G > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Draw the simplicial complexes from the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_subarray(original_array):\n",
    "    # Extract the subarray from the first 4 rows and first 4 columns\n",
    "    subarray = [row[:4] for row in original_array[:4]]\n",
    "    return subarray\n",
    "\n",
    "G_test_list = []\n",
    "\n",
    "for i in range(0, len(G)):\n",
    "    G_test = create_subarray(G_binary[i])\n",
    "    G_test_list.append(np.array(G_test))\n",
    "\n",
    "fixed_pos = {0: (0, 1), 1: (0, 0), 2: (1, 0), 3: (1, 1)}\n",
    "\n",
    "# Create a single figure with subplots\n",
    "plt.figure(figsize=(10, 7))  # Adjust the figure size as needed\n",
    "plt.title('Visualisation of the complete dataset')\n",
    "\n",
    "for i, graph_matrix in enumerate(G_test_list):\n",
    "    plt.subplot(2, 3, i + 1)  # 2 rows, 3 columns, current plot index\n",
    "    G_drawing = nx.from_numpy_matrix(graph_matrix)\n",
    "    nx.draw(G_drawing, with_labels=True, pos=fixed_pos)\n",
    "    plt.title(f'Graph {sheet_list[i]}')\n",
    "\n",
    "plt.tight_layout()  # Adjust layout for better spacing\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute the connection probability matrix $L_p$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_p = np.mean(G_binary, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute the inverse connection matrix ${L_i}^{-1}$**\n",
    "\n",
    "To do this we first have to get rid of the zero rows and column, since the matrix is not invertible if the determinant of the desired matrix is zero. When we did this we can generate the inverted matrix. So for example for the first matrix L_A this would go like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_matrix_generator(matrix):\n",
    "\n",
    "    # Find non-zero rows and columns\n",
    "    non_zero_rows = ~np.all(matrix == 0, axis=1)\n",
    "\n",
    "    # Store the indices of removed rows. This is the same for the columns since the matrices are symmetric\n",
    "    removed_rows = np.where(~non_zero_rows)[0].tolist()\n",
    "\n",
    "    # Extract the non-zero rows and columns\n",
    "    result_matrix = matrix[non_zero_rows][:, non_zero_rows]\n",
    "\n",
    "    # Generate inverse matrix\n",
    "    if np.linalg.det(result_matrix) != 0:\n",
    "        inverse_matrix_unrounded = np.linalg.inv(result_matrix)\n",
    "        inverse_matrix = np.round(inverse_matrix_unrounded, decimals=2)\n",
    "    else:\n",
    "        inverse_matrix = 0\n",
    "\n",
    "    return result_matrix, removed_rows, inverse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customize print settings to print the entire matrix\n",
    "#np.set_printoptions(threshold=np.inf)\n",
    "# Reset NumPy print options to the default settings\n",
    "#np.set_printoptions(threshold=1000)\n",
    "# OR use seaborn to show as heatmap or clustermap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate desired matrix\n",
    "matrix = G[4]\n",
    "\n",
    "print(\"Original Matrix:\")\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate matrix without zero rows and columns\n",
    "result_matrix, removed_rows, inverse_matrix = inverse_matrix_generator(matrix)\n",
    "\n",
    "print(\"\\nMatrix without Zero Rows and Columns:\")\n",
    "print(result_matrix)\n",
    "\n",
    "print(\"\\nIndices of Removed Rows/Columns:\", removed_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the inverse matrix\n",
    "if np.linalg.det(result_matrix) != 0:\n",
    "    print(\"Inverse Matrix:\")\n",
    "    print(inverse_matrix)\n",
    "else:\n",
    "    print(\"The matrix is singular and cannot be inverted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat this for the complete dataset, so that we end up with inverse matrices for $G_A$ to $G_F$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invert matrices for complete dataset\n",
    "L_inverse_list = []\n",
    "removed_rows_list = []\n",
    "\n",
    "for matrix in G:\n",
    "    result_matrix, removed_rows, inverse_matrix = inverse_matrix_generator(matrix)\n",
    "    L_inverse_list.append(inverse_matrix)\n",
    "    removed_rows_list.append(removed_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to decompress the inverse matrices for later use, since we need to multiple them with the $L_p$ matrix and thus should be of equal dimensions.\n",
    "However, decompressing is not that easy, because the stored indexation of the removed rows and columns is not the same as the place we should return zero rows and columns. To do this, below, we first decompressed the first row of the ${L_i}^{-1}$ matrix by inserting zeros at the indices of the removed columns. This decompressed row list then presents the location where zero columns (and rows due to symmetry) should be inserted into the ${L_i}^{-1}$ matrix. This happens in the next step, using the function add_zero_array for each zero value in the decompressed row list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to decompress the compressed array with inserting zeros at the indices of the removed rows and columns\n",
    "def decompress_row(array_length, index_removed):\n",
    "    \n",
    "    # Add +1 to each value in the index_list since the count starts at zero\n",
    "    index_removed = [x + 1 for x in index_removed]\n",
    "\n",
    "    # Create a complete array from 1 to 14\n",
    "    complete_array = np.arange(1, 15)\n",
    "\n",
    "    # Set every row index that is removed to zero in the complete array\n",
    "    for index in complete_array:\n",
    "        if index in index_removed:\n",
    "            complete_array[index-1] = 0\n",
    "\n",
    "    array_decompressed = complete_array\n",
    "    return array_decompressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a zero column at the desired index\n",
    "def add_zero_array(original_array, index, axis_choice):\n",
    "    \n",
    "    # Create a zero array of fitting shape\n",
    "    zero_array = np.zeros(original_array.shape[0], dtype=original_array.dtype)\n",
    "\n",
    "    # Insert the array into the original array\n",
    "    inserted_array = np.insert(original_array, index, zero_array, axis=axis_choice)\n",
    "\n",
    "    return inserted_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompress(matrix, array_length, removed_rows):\n",
    "    \n",
    "    # Decompress the 1D array\n",
    "    decompressed_1D_array = decompress_row(array_length, removed_rows)\n",
    "\n",
    "    # Insert zero rows/columns at the indices with value zero from the decompressed 1D array\n",
    "    for index in range(0, len(decompressed_1D_array)):\n",
    "        if decompressed_1D_array[index] == 0:\n",
    "            inserted_column_array = add_zero_array(matrix, index, 0) # The column axis is 0\n",
    "            inserted_row_array = add_zero_array(inserted_column_array, index, 1) # The row axis is 1\n",
    "            matrix = inserted_row_array\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the decompression on for example the fifth inverse matrix ${L_5}^{-1}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Complete decompressed 2D array:\")\n",
    "decompress(L_inverse_list[4], 14, removed_rows_list[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, repeat this for the complete dataset, so that we end up with decompressed inverse matrices for $G_A$ to $G_F$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_inverse_decompressed_list = []\n",
    "\n",
    "for matrix in range(0, len(L_inverse_list)):\n",
    "    decompressed_matrix = decompress(L_inverse_list[matrix], 14, removed_rows_list[matrix])\n",
    "    L_inverse_decompressed_list.append(decompressed_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate the internal energy U**\n",
    "\n",
    "To calculate the internal energy of any desired simplicial complex $G_i$ from the dataset, we need to multiply the decompressed inverse matrix ${L_i}^{-1}$ with the connection probability matrix we calculated before $L_p$. I.e. the calculation is as follows:\n",
    "\n",
    "$$\n",
    "U(p) = \\sum_{x,y} \\left( {L_i}^{-1} \\cdot L_p \\right)\n",
    "$$\n",
    "\n",
    "Test this for the fifth simplicial complex in the dataset $G_5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def internal_energy(inverse_connection_matrix, probability_matrix):\n",
    "\n",
    "    # Compute the internal energy\n",
    "    U = np.sum(inverse_connection_matrix * probability_matrix)\n",
    "    return U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_G5 = internal_energy(L_inverse_decompressed_list[4], L_p)\n",
    "print('The internal energy of G_5 is:', U_G5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate the entropy S**\n",
    "\n",
    "To calculate the entropy S of any desired simplicial complex $G_i$ from the dataset, we need to use the diagonal of the probability matrix $L_p$ as follows:\n",
    "\n",
    "$$\n",
    "S(p) = - \\sum_{x} p(x) \\cdot log \\left[ p(x) \\right]\n",
    "$$\n",
    "\n",
    "Test this for the fifth simplicial complex in the dataset $G_5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(connection_matrix, probability_matrix):\n",
    "\n",
    "    # Generate probability matrix specific to the simplicial complex G_i\n",
    "    specific_probability_matrix = connection_matrix * probability_matrix\n",
    "\n",
    "    # Extract the diagonal values as a list\n",
    "    diagonal = np.round(np.diag(specific_probability_matrix).tolist(), decimals=2)\n",
    "\n",
    "    non_zero_diagonal = [value for value in diagonal if value != 0]\n",
    "\n",
    "    # Compute the entropy\n",
    "    S = - np.sum(non_zero_diagonal * np.log(non_zero_diagonal))\n",
    "    \n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_G5 = entropy(G[4], L_p)\n",
    "print('The entropy of G_5 is:', S_G5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate the Helmholtz free energy F**\n",
    "\n",
    "From the entropy S and the internal energy U that we just found, we can compute the Helmholtz free energy F using the relationship:\n",
    "\n",
    "$$\n",
    "F = U - T \\cdot S\n",
    "$$\n",
    "\n",
    "Where we choose a fixed value for T, since we assume that the temperature is constant for all simplicial complexes in the dataset. Let's take the temperature to be T = 293 K. Again, test the formula for the the fifth simplicial complex $G_5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def free_energy(internal_energy, temperature, entropy):\n",
    "    return internal_energy - temperature*entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 293\n",
    "F_G5 = free_energy(U_G5, T, S_G5)\n",
    "print('The Helmholtz free energy of G_5 is:', F_G5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the dynamics of the functionals**\n",
    "When we apply the free energy computation to the real data, it is desirable to compare the dynamics of the entropy, internal energy and free energy against some property of the dataset. For example, to verify the free energy principle, i.e. how the free energy is minimised over time. To do this efficiently, below we explore some useful ways to plot the dynamics of the functionals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the functionals from the dataset\n",
    "def functionals(G_matrices, L_matrices, L_p, temperature):\n",
    "    U_list = []\n",
    "    S_list = []\n",
    "    F_list = []\n",
    "    for matrix in range(0, len(L_matrices)):\n",
    "        U = internal_energy(L_matrices[matrix], L_p)\n",
    "        U_list.append(U)\n",
    "        S = entropy(G_matrices[matrix], L_p)\n",
    "        S_list.append(S)\n",
    "        F = free_energy(U, temperature, S)\n",
    "        F_list.append(F)\n",
    "    return U_list, S_list, F_list\n",
    "\n",
    "U_list, S_list, F_list = functionals(G, L_inverse_decompressed_list, L_p, 293)\n",
    "print(U_list)\n",
    "print(F_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the functionals from the dataset\n",
    "def functionals2(G_matrices, L_matrices, L_p, temperature):\n",
    "    U_list = [internal_energy(L, L_p) for L in L_matrices]\n",
    "    S_list = [entropy(G, L_p) for G in G_matrices]\n",
    "    F_list = [free_energy(U, temperature, S) for U, S in zip(U_list, S_list)]\n",
    "    return U_list, S_list, F_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise the data\n",
    "def normalisation(data):\n",
    "    min_val = min(data)\n",
    "    max_val = max(data)\n",
    "    normalised_data = [(x - min_val) / (max_val - min_val) for x in data]\n",
    "    return normalised_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call functionals\n",
    "U_list, S_list, F_list = functionals(G, L_inverse_decompressed_list, L_p, 293)\n",
    "# Normalisation\n",
    "U_list, S_list, F_list = normalisation(U_list), normalisation(S_list), normalisation(F_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the functionals for all simplicial complexes\n",
    "x_values = list(range(len(U_list)))\n",
    "plt.scatter(x_values, U_list, label='Internal Energy')\n",
    "plt.scatter(x_values, S_list, label='Entropy')\n",
    "plt.scatter(x_values, F_list, label='Free Energy')\n",
    "\n",
    "plt.xticks(x_values, sheet_list)\n",
    "plt.xlabel('Simplicial Complex')\n",
    "plt.ylabel('Relative value')\n",
    "plt.title('Functionals vs Simplicial Complex')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TDA_brain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
